diff --git a/torchtune/datasets/_preference.py b/torchtune/datasets/_preference.py
index 6b7c6294..059d46a7 100644
--- a/torchtune/datasets/_preference.py
+++ b/torchtune/datasets/_preference.py
@@ -129,21 +129,25 @@ class PreferenceDataset(Dataset):
         return self._prepare_sample(sample)
 
     def _prepare_sample(self, sample: Mapping[str, Any]) -> dict[str, list[int]]:
-        transformed_sample = self._message_transform(sample)
+
+        prompt_tokenized = self._tokenizer.encode(sample["prompt"])
+        prompt_mask = [True] * len(prompt_tokenized)
+        chosen_tokenized = self._tokenizer.encode(sample["chosen"])
+        chosen_mask = [False] * (len(chosen_tokenized) - 1) + [True]
+        rejected_tokenized = self._tokenizer.encode(sample["rejected"])
+        rejected_mask = [False] * (len(rejected_tokenized) - 1) + [True]
+
+        chosen_input_ids = prompt_tokenized + chosen_tokenized
+        rejected_input_ids = prompt_tokenized + rejected_tokenized
+        chosen_masks = prompt_mask + chosen_mask
+        rejected_masks = prompt_mask + rejected_mask
 
         # TODO: Truncation differs from original DPO repo
         # in DPO: first truncate prompts, then responses
-        chosen_input_ids, chosen_masks = self._tokenizer.tokenize_messages(
-            transformed_sample["chosen"],
-        )
-
         chosen_labels = list(
             np.where(chosen_masks, CROSS_ENTROPY_IGNORE_IDX, chosen_input_ids)
         )
 
-        rejected_input_ids, rejected_masks = self._tokenizer.tokenize_messages(
-            transformed_sample["rejected"],
-        )
         rejected_labels = list(
             np.where(rejected_masks, CROSS_ENTROPY_IGNORE_IDX, rejected_input_ids)
         )
